# The Implicit Model: A Concept for Research, and a Case for Thinking, Objectivity, and Theory

**Presenter:** Patrick Stinson
**Source:** YouTube Video Transcript
**URL:** https://www.youtube.com/watch?v=-awpKaUsySA

---

## Introduction

I'm going to present some of my thinking from the last while—more than a couple of years. This is entitled "The Implicit Model," which is a concept that makes a case for thinking, objectivity, and theory.

I'm going to attack the summary for this in a few different ways. In the shortest form, the question I'm getting at (the one I began with—though I think I've moved beyond it) is: **What exactly is a Bowen coach getting paid for if they don't fix anything?**

That question is like: how do you explain this to somebody who doesn't know theory and doesn't know all the complexities required to answer the question? I've been playing with that question.

I thought it would be an interesting exercise to say: what is the elevator pitch for Bowen theory, to be as short as possible—just one paragraph, a short paragraph? It's also getting at: what is the theory of change in Bowen theory?

### The Elevator Pitch

The best thing I've come up with so far (and I don't think it's good enough) is this three-clause statement, which I'm going to break down over the course of the presentation:

> 1. The way a person understands a problem determines what they do to solve it.
> 2. The validity of that understanding determines the efficacy of that solution.
> 3. The goal in the application of Bowen theory is to assist a person in making their model of the problem as accurate as possible.

There's a lot in here. Some authors have written "the way a person thinks about a problem determines what they'll do to solve it" or something like that. I'm replacing it with "understanding" to make it broader, because I'm going to go deeper with this. The term "validity" points to this objectivity term.

How best to understand all of this completely objectively? What's a theoretical basis for this? If this is so, how to understand how this works—to come up with a way to explain it, to account for it?

I think that requires a new concept. When I try to explain this, I need to elaborate on this elevator pitch, and that requires a new concept to unite a lot of these different pieces.

### Overview

In summary, I'm going to:
1. Explain the concept of the implicit model in brief form
2. Describe how the terms emotion, value, and thinking fit into that model (raising "value" from just a humanistic or human term into a technical theoretical term, related to emotion and guidance)
3. Talk about how implicit models (or functional models) evolve over time, which forces the concept to be more sophisticated and rich, to be better thought through

---

## Part 1: What Is the Implicit Model?

In short, the implicit model is a **guidance system**. It is a guidance system of the context that the system confronts—that which guides behavior—implicit meaning "in a living thing."

### The Dilemmas

There are all these dilemmas when you start using terms like objectivity, thinking, religion, and science. These are **anthropocentric terms**—they center around humans and require human subjectivity to be defined.

But I've implicated objectivity in my elevator pitch and used somewhat scientific language. So:
- How to understand the term "objectivity" in a cross-species manner? What is objectivity to ants and bacteria?
- Is thinking merely a human function, or is it an elaboration of a basic pattern? Can it be described in such terms?
- Even wackier (and I won't get to this till the end): what exactly is religion, functionally? What's the function of religion in a cross-species manner, without anthropomorphizing?

This gets at the potential for a **ninth concept** in the sense that: what do you do when somebody has a heuristic or a model of a problem that is factually inaccurate but more adaptive, at least for a certain context? This term "Darwinian truth" is an interesting angle on that—when is it that a truth is more adaptive than a fact, or how do you account for it?

Same thing with science: if science is an adaptation, how do you understand it in a broader context outside of just the human species?

### Terms I'm Placing Off Limits

**Consciousness** is the big one. I don't like the term because I've never heard an objective definition of it that doesn't require another subjective term like "awareness," "experience," "choice," or "free will."

These terms are subjective because they tend to self-reference. When one person defines consciousness, they usually rely on a term like "awareness" or "experience" as if that captures it. But when you try to define those terms, they usually require consciousness or something like that. Circular definitions don't do it for me. I think there's a ton of subjectivity in there that most people who define this in public don't realize, and I'll stand by that.

The other question is: if you've got definitions for these, how does that relate to what's going on in coaching? How does that relate to research in natural systems? All of these things have to be addressed and related to each other if you're going to develop a theoretical system.

---

## Part 2: Definitions

### Theory and Model

The one word for "the way a person understands a problem" (from the elevator pitch) is **theory**. Theory is information about how something works—theory can be used to make predictions about the thing that the theory describes.

A **model** is a device that produces that prediction. It's a simulation of the thing described by the theory. It's not the thing itself—that's why it's called a model.

There are theories that describe how the weather works. These theories can be used to construct a model that predicts the weather. The model may be:
- A computer program
- An algorithm worked out with paper and pencil
- Just an if-then statement run through someone's head

A weather model is not the weather itself. It's not all the things that go into weather—water, gases, photons, particles of dirt, rock, etc. It's an algorithm that calculates what all those materials do. Therefore, a weather model does not behave exactly the same as the weather itself.

**Every model predicts with error** because the model is not the same as the thing being modeled. Error is going to be a central variable in this implicit model concept.

### Core Assumptions

Every person has a model of a problem they're dealing with. These are the assumptions that this concept implies:

1. **If they're behaving, they have a model determining the behavior.** The model is determined by a theory.
2. You can begin to get at a person's theory of a problem by asking them to describe the problem. Their theory may or may not be accurate.
3. **A person has both:**
   - A model that they *think* they have
   - A model that their behavior *actually reveals*
4. The model that they think they have is an **explicit theory**.
5. The model that actually guides their behavior is an **implicit model**. (Key distinction.)
6. The model is **explicit** when a person explains it verbally, codifies it on paper, or with building materials.
7. The model is **implicit** when it's implied, or when it operates automatically within the individual.

The term "implicit model" is only a concept. If you look in the organism, you're not going to find it. The organism functions *as if* it has an implicit model. The concept is just an artifact of subjectivity—it's just a tool we use to understand. It's not a fact.

This gets into the Darwinian truth idea: when you have something that's not a fact but is adaptive nevertheless to use.

### Application to Bowen Theory

**Bowen theory describes the behavior of the implicit model in the human family.**

Bowen theory is an explicit theory because it's written down and spoken out loud. The suggestion here is that the family has an implicit model that determines every aspect of its behavior. It is an implicit model because it operates automatically within the family.

**The implicit model is the emotional system itself.** It's the natural "guidance system" that is being studied.

However, the implicit model of the human family has actually not been discovered. Because if it had, an explicit model of the family's implicit model would exist—there would be a family simulator.

This discovery came as a shock to me. I was sitting there watching Ian Couzin's fish models and I thought, "Well, we've got Bowen theory and I have the skills to write this kind of code. I can just write it down. I have to do it! I'll do it tomorrow at noon."

And I sat down and I'm like, "Wait a second. I don't know what the variables are. I don't know how they interact. It's just not there. It doesn't exist yet. It has to be developed."

**Bowen theory only describes what the family emotional system does under specified conditions. It doesn't define how it accomplishes this.**

In this sense, Bowen theory simply defines the requirements for how an explicit model of the family would behave. Such an explicit model would define the universal script that every family member would follow from their own unique point of view. That's effectively an agent model.

The result would be a family simulation that would automatically exhibit the emergent behaviors described in at least six of the eight concepts of Bowen theory—without those concepts being explicitly programmed in. They're emergent behaviors, not determined behavior. They automatically appear at the level of the group when all you've done is program a universal script for the individuals.

### Explicit vs. Implicit

One human may behave based on assumptions that are more implicit (i.e., unknown) than another.

Interestingly, it does appear that when a thinking system defines and refines an explicit model about its own behavior, the change in the explicit model bleeds into the implicit model. The implicit model is then changed.

For example: seeing a triangle can actually change the level of automatic reactivity a person exhibits within that triangle.

**The goal is for the model to predict the future context with as little error as possible.** That's the goal of this implicit model.

A word for this ability may be "objectivity"—and this begins to hint at the possibility of a cross-species definition of objectivity.

### Cross-Species Objectivity

A cross-species definition of objectivity would be in line with the assumption that complex forms of life (like the human) are more or less elaborations of basic patterns of organization in all of life. The concept of an implicit model makes a cross-species definition of objectivity possible—may not be the right one, but it makes it possible.

So maybe **the application of Bowen theory is the effort to make the theory of a problem as accurate as possible.** And as I'll show later, differentiation in the coach, knowing theory, thinking systems—all play into this singular goal, these functions of a coach. What the coach does after that is up to them, of course.

### The Thesis

To be clear, the thesis here is that an implicit model is not a tool that a person chooses to use. **It determines every aspect of that person's behavior.** It's automatic. It is that which is automatic.

The proposition here is that when someone studies their own behavior or someone else's behavior, they are inferring that person's implicit model. This points to the function of the research effort—whether in formal research, coaching, or differentiating oneself.

As the coachee's (the person being coached's) explicit theory of the problem changes, then both the implicit and explicit models of the problem automatically change with it, to varying degree.

As far as I can tell, this is a way of understanding why Bowen repeatedly wrote that he was more interested in developing theory than merely developing therapy. Because **therapy is determined by the model, and the model is determined by the theory. Advances in theory automatically convert to advances in therapy** (so long as...). And efficacy is determined by the validity, of course.

Again, how to account for this theoretically? It's given as an assumption, but how to understand how this works?

---

## Part 3: How Emotion, Value, and Thinking Relate to the Implicit Model

I'm sure many of you are familiar with Lisa Feldman Barrett and Antonio Damasio. There are a lot of theorists out there saying similar things. There are some differences, but these are important researchers.

### Lisa Feldman Barrett

Feldman Barrett is a really interesting theorist, quite an accomplished researcher. She's famous for showing that there are no discrete emotions or feelings, and that we're not actually as good at detecting them as we think we are on sight.

She uses the term **prediction** to organize how behavior is guided. This is a common concept in neuroscience, and it fits with the idea that the behavioral system functions *as if* it's predicting. That's a concept—an artifact of subjectivity, not a fact.

She says:
- Predictions are constructed in a real-time stream (as opposed to discrete, sporadic events)
- Behavior itself is an ongoing prediction
- You can change the way your automatic predictions occur (transference, for example)—you can have an impact on that, to make it more accurate

She does not, I think, effectively or intentionally distinguish between the terms "emotion" and "feeling" as they're distinguished in Bowen theory. She implies that emotions are constructed in real-time based on the perceptual system and evaluation.

She does not necessarily use concepts that scale to multiple levels of analysis, where each level of analysis (say, the individual and the family) is involved in the co-construction of emergent phenomena, of guidance.

### Antonio Damasio

Damasio is just so interesting. He uses the term "emotion" and describes it often as:
- Always having a **positive or negative valence**
- Always having an **intensity**
- Never neutral
- Integral to the act of perceiving

He uses the term "motivation" as a concept. He says feelings are the brain working in contact with the body, by definition.

He has a great definition for "self" (another term I don't generally like, outside of immunology's more objective definitions): translated into Bowen theory terms, it's basically **the brain's sense of the over-functioning and under-functioning balance of the body's physiological systems, via sensational information**—information from bodily sensation.

I'm not saying a whole lot new here, but I do think I'm framing it in a slightly different way.

---

## Part 4: The Fundamental Challenge and Functional Adaptation

Taking a step back for a deeper dive: the key assumption here is that **one way to conceptualize the fundamental challenge for any organism is to persist in the face of change.**

I think it's easy to anthropomorphize evolution as if there's an agent behind it, as if it's acting out of will. That comes out in people thinking and talking as if they can actually have an impact on evolution—which I think is actually illogical. It's an assumption: if you're going to assign a goal, you're inserting subjectivity. Let's say the goal of life is to persist. Proceeding with that assumption makes a conversation possible. But that part's an assumption.

Let's say it's to persist **in the face of change** in particular, because "all things change" is a fact.

It might be assumed then that the fundamental clinical (or coaching) challenge is to assist a person or a family in adapting to change.

### How Organisms Adapt to Change

The thesis proposes a conceptualization for **functional adaptation** (as opposed to merely structural adaptation):

An organism adapts to change by relying on a **predictive model built into the species**. This implicit model is encoded in the organism's physiology, just as the currently active algorithm of a computer is encoded in the physical network of transistors. The model exists in the **information domain**, not the physical domain.

The predictions generated by the implicit model are, theoretically speaking, **a perfect statistical representation of the organism's context over the course of its evolutionary past**—a perfect statistical representation. This is just the suggestion of the concept.

The model therefore functions to make statistical predictions of the current context based on:
- What is perceived in the present moment
- Recalled conditions of the past

"Statistical" here means just probabilistic—it's making a best guess.

But as with all statistical predictions, these predictions contain a degree of **error**.

**The concept here is that the struggle of life is equivalent to this error.** It's a basic concept—not just a choice, not just something used from time to time—but a way of conceptualizing how behavior functions, how it works.

### Examples of Prediction Error

- One person is continually rejected for jobs while another is not. What is it that the first person was not able to predict about their rejections? In retrospect, why put forth the effort at all if that's the reality? There was a failure of prediction.

- Another person may be constantly sick, in part because they repeatedly choose improper clothing for the day's weather. Their behavior operates on the erroneous prediction that they are adequately prepared for the day.

- Another person may waste time in a busy day because they drop their belongings every few minutes. Their "clumsiness" implies that they incorrectly predicted they had a sufficiently firm grip on their phone, or balance in their shoes, or eyes on the road. There's a constant failure to predict.

Errors in prediction accumulate from moment to moment, throughout the day, leading to an overall **ease or disease** while moving through life in general.

This could be one aspect of progression and regression in multi-generational transmission. Considering the basal level of this concept, it's going to be right there next to differentiation—or maybe just a slant on differentiation. The question of their relation is a big and important one.

**The model is implicit.** It functions outside of awareness. It governs the function of the heart and diaphragm just as much as the deliberate choice of clothing.

---

## Part 5: Emotion

For the purposes of this thesis, **emotion is synonymous with action**.

Emotion is directed by predictions from an organism's model. The model functions to carry out something like the calculations for landing a guided rocket on a distant asteroid. In these calculations—which represent predictions based on the laws (or theories) of physics—emotion is something like the energetic propulsion of the rocket and the movement of its various control mechanisms, in accordance with the calculations.

The energy is in line with the calculations, but they are not the same thing.

Through this conceptualization, **emotion is the observable physical outcome of a statistical best guess for what the context will be**. The model's prediction occurs at the information level; emotion occurs at the physical level.

I'm using the word "context" instead of "environment" because context is broader and encompasses the state of everything in the universe at that moment. It includes what is external to the organism and what is internal to the organism. "Environment" always kind of sounds like it means outside.

### Emotion Is Always Partially Appropriate

Because the model's prediction is a perfect imprint of the past, and the events of the past are more accurate than inaccurate predictors of the future (by virtue of the organism's survival), **emotion is always at least partially appropriate**.

This is why emotion can neither be ignored nor allowed to fully determine action.

**The goal is to get the expression of emotion as in line with the present context as possible.** This is about efficiency. Organisms that direct emotion accurately through extreme changes in context tend to survive.

---

## Part 6: Value

**Value is the "value" in evaluation.** Value is the product of the implicit model. It is the result of combining:
- Sensory input from the moment
- Memory of sensory input from the past

In the implicit model concept, **value represents guidance** generated by the model. They're synonymous so far.

Value can be conceptualized as:
- A **desirability valence** (whether something perceived is desirable or undesirable)
- The **intensity** of that desirability

Go towards the desirable; go away from the undesirable.

If emotion is automatic and defined as having valence plus intensity, then we have an **emergent value system built into biology**. Or you could say there is an **emergent ethic co-created in the interaction of natural living systems**.

This gets at the religion question that I'll return to at the very end—an emergent value system.

Value is the guidance, which is the result of an evaluative process. I'm effectively equating this to what people generally call the psychological function of the individual—or you might expand it to say the psychological function of the cell, or the psychological function of any emotional system. The term "psychological" is obviously inadequate for that description, but it begs a description for the information-processing level—the part that makes predictions and produces guidance. I'm using the term "value" here in a technical manner.

An emergent value system built into biology.

### Updating the Model

How then to most efficiently update an organism's model in the face of constant change? How to make a model more flexible?

In the rocket analogy: you've got the turn-left, turn-right problem. How far to turn left, how far to turn right? This would be equivalent to guidance—the valence. It's direction. What are you aiming at? That would be value.

**If objectivity is the ability to process information related to the context more accurately and more efficiently**, then does this conceptualization provide a case for objectivity as a central characteristic of a biological adaptation?

Is there a better term to replace it? Does this perhaps suggest an objective definition of objectivity—one that applies to all of life instead of depending on the human? What is objectivity in a broader sense?

This is one of the main questions I'm wrestling with here.

---

## Part 7: Thinking and Feeling in a Single Frame

All of this puts thinking and emotion into a single frame of reference.

Some organisms adapt their model faster than others. Presently, humans can change their model far faster than any other organism—so long as persistence is the goal (and that's what we're talking about). At least in relation to the context we see on Earth today.

Who knows? Maybe there are microbiota that can survive in an even greater range of context. I'm not sure what the most adaptive forms of life are from that frame of reference. If persistence is the goal, maybe simplicity is better in some contexts than others. I'm not good at this range of literature, so I could draw on others for that.

### The Implicit Model Concept Unifies Thinking and Feeling

**Emotion and thinking simply function to better predict the context.** They're not even actually separate functions in this view.

All mammals possess a cortex. Of the mammals, the human has the most complex cortex. But there's debate about which animals possess a neocortex (at least in terms of structure), because some mammals exhibit cognitive processes typically associated with the neocortex—some birds, for example—without possessing neocortical structure.

So maybe there's a way of understanding the function that's occurring in a broader frame of reference.

From the frame of reference that puts thinking and feeling into the same function of prediction, **all animals have a proto-thinking system**. That is to say: humans also have a proto-thinking system—in relation to whatever species may possess a more complex cortex in the future.

Either way, each species would be expressing a similar **morphogen** (or set of morphogenes) at varying degrees of complexity and/or maturation. Morphogenes are the unit of information that guide the development or evolution of physiological structure. ("Morph" is form; "gene" is origin.)

Maybe thinking is just an elaboration of a process that exists in simpler forms of life—a more complex quantitative difference instead of a qualitative difference.

Thinking that humans "differentiated a thinking system" certainly suggests it's more of a qualitative difference. That view may have utility. I think that way.

In any case, the implicit model implies—and this is key—that **the thinking function simply enhances the function of emotion in a predictive model of the context**, and that they're really the same function.

### A Definition of Thinking

From this frame of reference, **thinking is simply the consideration of a broader range of sources of information in the act of prediction**.

That's a quantitative difference, because emotion (under the definition so far) is the result of a statistical calculation based on sense data and memory of sense data. So it is considering sources of information.

Thinking just adds more sources of information in the model's prediction. It does this using all the things we associate with the prefrontal cortex (like emotion inhibition and so on)—but always to the same end of prediction.

### The Principle of Assessment

If persistence is assumed to be the goal, then **error in the model can be used to evaluate the model**.

I'll cover a dimension of evaluation in the next section on the evolution of functional models.

---

## Part 8: Application to Coaching and Research

Back to the explicit model idea. An explicit model is constructed by humans.

One advantage of the implicit model concept is that it's a way to think about what occurs in behavioral research from a natural systems perspective—and you can throw coaching in there from the perspective of Bowen theory.

For the biological behaviorist, **an explicit model is an attempt to simulate an implicit model**. From the frame of reference I'm throwing out there, it is the goal of a biological behaviorist to construct a model that accurately shows you understand the implicit model at work that guides the behavior of the system.

### Same Concept for System and Research

One advantage of the functional model idea (implicit and explicit models are both functional models—the implicit model is the interesting one) is that it **conceptualizes both the system being studied and the goal of research itself (or even coaching) in the same manner**.

The same concept applies to every situation: to define the functional model at work. To use the same concept to understand:
- What you're studying
- What you're doing
- What you're actually constructing in research

This can potentially be assessed objectively: how much error is in this model?

---

## Part 9: How Do Functional Models Evolve?

This is the funnest section to me. It's partially speculative.

How do functional models change over time? How do they evolve? How to understand if there's a single dimension along which they progress, or if they're just a wave in the ocean of context?

### Differentiation of Function

All of us are familiar with the idea of differentiation. A hypothetical situation:

Imagine a very, very simple living system—subcellular even, or single cell—that can maintain equilibrium (i.e., survive) in fluid, but only in a certain temperature range. In order to survive in fluid that fluctuates in a broader temperature range, it has to **differentiate a function**—the ability to modulate its processes so it can stay intact, stay alive, as the temperature changes. Let's say it grows another little part. Now it can do two things instead of one thing.

To survive outside the liquid, maybe it has to have some other ability—like going into hibernation so it can dry out and then re-instantiate itself.

The idea is that it's **stacking on functions**. Those functions more or less differentiate—they specialize. Functional differentiation.

### The Critical Point

But then a critical point is reached. (Some of this speculation comes from my experience in computer science, because I believe computer science fundamentally is the science of functional models—learning how functional models are organized and evolved. People are starting to use biological terms to describe the most bleeding-edge computer science concepts. There's something very interesting going on there. It's our best model of what's written in nature—just the science of software, not the actual software, but the science of software.)

A **critical point of scalability** is reached where the system just can't maintain more differentiated functions. It's reached a critical capacity of complexity—a critical mass of complexity.

In order to continue to adapt, it has to go through a **fundamental reorganization**—which is not differentiation. It's a **simplification**.

While the differentiation phase applies to the individual components/functions of the system, that reorganization pertains to **the system as a whole**. You have elements within the system (functions) that are differentiating and specializing. Then you have something where it just can't do that anymore and it has to redefine itself at the broader level.

**The key:** The new functions are gained while the old functions are still maintained. So it's not another specialization—it's a redefinition. It's something more basic.

I don't know what to call this. It's not "integration." It's not the opposite of differentiation. But it's something that works in tandem.

Because it works at the level of the greater system, I think this is what the Eastern and holistic traditions (let's call them "wisdom traditions") are describing. There's a holism that has come from a lot of the spiritual world that describes something about how individuals progress. I think there's something about this second phase that is just what they're talking about.

It has to do with **more efficiently adapting to the context using less energy to do more**. That's why I'm saying "retaining old functions while gaining new functions." There's a simplification that happens—not more differentiation, more divergence, more complexity.

### An Example at the Individual Level

An example at the individual level (maybe at a family level—maybe a really fused family):

"I used to have a different persona for everyone I would interact with all day. And I learned how to define who I was—I reorganized, fundamental reorganization. And now I am just me. It takes a lot less energy, it's more effective, and I get more of what I want."

Maybe there were a few old functions that were shed. The person didn't lose the ability to have those old functions, but they certainly lost their priority.

There's something about that. It points at another level for differentiation that the term "differentiation" (as a research term, as a technical term) doesn't capture. I think there's another phase there. Jan Sapp was onto it, maybe.

### Paradigm Shifts

A new *Homo sapiens* species would, I speculate, represent this kind of shift—this second phase—some kind of fundamental shift in conceptual systems (which are functional systems; all of software is the study of conceptual systems).

Every serious software engineer is a theorist—I don't think they even realize it at the time.

Conceptual systems, when they go through this second phase, it's called a **paradigm shift**. It's where the individual components (the concepts in the conceptual system) were differentiating and increasing in complexity; the disparate models were increasing in number. But the old organization, the old paradigm, didn't work anymore.

In the fundamental reorganization, you won't even really see the old concepts or functions—you'll just see remnants of them, traces. They really don't make sense in the new system anymore. It's not even possible to translate. It's a big shift.

---

## Part 10: Guidelines for Natural Systems Theory

I've defined these guidelines for natural systems theory. There are currently nine of them. They came out of the Bowen literature—I inferred them from Bowen theory. A lot of it came from Kerr's writing when he was talking about what systems thinking is.

**They are a definition for systems thinking.**

In brief (this totally does violence to them—you can't really understand what they are from looking at this, but it gives you an idea):

They're basically what goes into a paradigm of emotional systems. An emotional system model would have these characteristics. A more sophisticated model would increase along each one of these dimensions—it would have more of each characteristic.

I have a whole video on this (an hour long), and I've written this out in verbose form in my dissertation, with examples and citations from the Bowen literature.

### Progression and Regression

To show the principle: there are dimensions along which models increase when you think "systems" (particularly natural systems thinking). You produce models that increase along these dimensions.

Each one (on the left) regresses into the ones on the right:
- You start ignoring facts → your view becomes more partial, incomplete
- You stop thinking in terms of facts → more in terms of preconception and reduction, more about statistics
- You fail to think in terms of processes → you end up in static categories like the DSM
- You regress towards cause-and-effect thinking → away from reciprocity

**More conservative models have more of all of these (on the left).**

---

## Part 11: The Religion Question and the Ninth Concept

To tidy this up and touch on the religion question:

It's a dilemma to lay down a theoretical basis for what objectivity is—and if it helps humans, does it exist anywhere else? Is it actually unique to humans? Maybe in one frame of reference it is, but maybe it's an elaboration on a more basic pattern.

Same thing for thinking: if thinking is the consideration of a broader range of sources of information in the prediction and guidance of behavior, then maybe there are certain naked mole rats that can do this better than other naked mole rats. Broader thinking.

### What Is Religion Functionally?

The religion one is such a fun one—especially with the collective intelligence literature. What is the function of religion in a cross-species manner? What is religion? How to understand that in a broader sense?

There's a wonderful set of debates (four of them, sold out to thousands of people) between Sam Harris and Jordan Peterson. They were tangling with a problem that a **ninth concept of Bowen theory** would address, I believe.

They were debating a definition of truth. But really they were operating under assumptions in line with Bowen's paper on subjectivity ("Homo Sapiens and the Science," I think—if I got the order right) about the difference between truth and fact.

### Darwinian Truth

There's this term that came up: **Darwinian truth**—when you have a system of thinking or a model (using the terms I've thrown out there) that is factually inaccurate, obviously factually inaccurate, but is more adaptive.

What do you do with that? How do you understand that in the same frame of reference as a scientific theory, as any of these other natural systems concepts?

"Darwinian truth" in the sense that it leads to better adaptation—it's more adaptive.

**The example:** You treat a gun as if it's always loaded, even when you know for a fact it's not loaded. That's irrational—unless you take it in a broad enough context, which is that the behavior over time is better for survival because you don't kill yourself.

This focus on facts misses a nuanced understanding of how species adapt—of what is adaptive and what's not.

The potential for a ninth concept could get at that. It gets at: **what is religion in a broader sense?** Same thing with science. If whatever the "science thing" is is adaptive, and there was this crazy phase transition that really took off in the European Enlightenment (with its beginnings far earlier), but there are these phases that the human species is going through—how do you understand that with other organisms?

That's what this concept is. When you start thinking in terms of prediction, error, automatic models versus explicit models—it at least organizes a way to think about these questions.

---

## Conclusion: The Theory of Change

This gets at the theory of change in Bowen theory, in a manner that can also be used in research.

The elevator pitch again:

> 1. The way a person understands a problem determines what they do to solve it.
> 2. The validity of that understanding determines the efficacy of that solution.
> 3. The goal in the application of Bowen theory is to assist a person in making their model of the problem (or problems) as accurate as possible.

This gets at these terms about objectivity. "Validity" points to objectivity—and how to understand this in a broader context. That's what the concept was for.

I'll leave it at that. I'm looking for critique. I want to know where this is wrong—misrepresentation of any theoretical concepts, misrepresentation of accepted concepts in evolution, all of this stuff.

Thank you.
